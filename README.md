# HackUMBC2017: 
# Pocket Chef

## Inspiration
Since a very prominent issue in cooking using a recipe is that most people obtain their recipes online or on their phone and afterwards have to figure out how to properly display it without touching their device while cooking. That's very hard to do on your phone since you have to scroll through the recipe and same goes for the laptop. That's how we came up with the idea to display the recipe on your watch and be able to scroll through entirely hands free using motion gesture.

## What it does
(Phone) the mobile portion of our application allows for the user to find a recipe that they prefer wether it is on a website, or they would like to search for it themselve. They are able to find the recipe and send it to their smart watch application when they are ready to cook

(Wearable) Being able to recive a recipe or search for one using voice search. It allows you to go through the recipes using only gestures without ever needing to touch the screen of your watch or phone.
## How we built it
Using Android Studios we build a mobile and wearable application. We had a recipe class which allows us to orginiaze the recipes and format them for when they need to be transfered to the watch and can be broken down into the title screen, ingredient screen and all of the individual steps.

## Challenges we ran into
We had too many goals which were not fesible in the period of time we were given. It took us a while to set up concrete ideas of what we were specifically doing and how. We were unable to sucessfully get recipes from the internet or use the voice feature to search for recipes through the watch. 

## Accomplishments that we are proud of
We made a working prototype that uses the recipe class to generate the recipe on the watch. The watch app is able to format and generate the recipe for its purpose and you are able to scroll through all the content strictly using gestures without ever needing to touch the screen making the expirence hands free.

## What we learned

We learned how to bring together the McCormick's API and IBM BlueMix API. We used IBM BlueMix for setting up the URL that we are using as an access point for the McCormick API.

We also learned how to implement a mobile application onto wearable technology.

Although not yet implemented, we learned about IBM Watson's Visual Recognition API that was to be used to recognize images of food and search for relevant recipes using the McCormick API.

## What's next for Pocket Chef
We still have a lot of components of this application that we were not able to implement and all of those components tackle very interesting and complex tasks that our team is looking forward to tackling next chance we get to work on the app.


